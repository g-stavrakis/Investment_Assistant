{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QA dataset to index\n",
    "data = pd.read_csv('../data/investment_data.csv') # Could be the sample \n",
    "records = data.to_dict(orient='records')\n",
    "# Load the ground truth dataset\n",
    "ground_truth_df = pd.read_csv('ground_truth.csv')\n",
    "ground_truth = ground_truth_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Ranking Metrics\n",
    "\n",
    "For this section we will create some ranking metrics to evaluate the perfromance of different retrieval methods. More specifically we will examine:\n",
    "- **Hit Rate (HR) at k**: Counts from all the retrieval requests, how many of them contained the relevant documents in the top k results\n",
    "- **Mean Reciprocal Rank (MRR)**: Takes into account also the rank of the relevant document, with responses with the relevant document ranked higher with have a bigger score\n",
    "\n",
    "To learn more about these measures read: [20 Popular Machine Learning Metrics. Part 2: Ranking, & Statistical Metrics](https://medium.com/towards-data-science/20-popular-machine-learning-metrics-part-2-ranking-statistical-metrics-22c3e5a937b60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Hit Rate metric\n",
    "def hit_rate(relevance_total):\n",
    "    # Find the number of relevant documents from the retrieved documents\n",
    "    return sum(any(line) for line in relevance_total) / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MRR metric\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate different search_functions\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for record in tqdm(ground_truth):\n",
    "        record_id = record['id']\n",
    "        # Create a request for each query in ground truth\n",
    "        results = search_function(record)\n",
    "        relevance = [d['id'] == record_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'investment-info'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the client \n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Create the Schema of the Elastic Search Index for Keyword search\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"context\": {\"type\": \"text\"},\n",
    "            \"ticker\": {\"type\": \"keyword\"}, \n",
    "            \"company\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"investment-info\"\n",
    "# Check if the index exists\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    # Delete the existing index\n",
    "    es_client.indices.delete(index=index_name)\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [00:13<00:00, 510.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fetch all the documents into the elastic search index\n",
    "for record in tqdm(records):\n",
    "    es_client.index(index = index_name, document=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameteres to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a keyword search function to retrieve document form the elastic search\n",
    "def keyword_search(query, company, boosting):\n",
    "    # Create the query\n",
    "    search_query = {\n",
    "        # Specifying the number of documents to be retrieved\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        # Add the user query\n",
    "                        \"query\": query,\n",
    "                        # Include the text fields to search\n",
    "                        \"fields\": [\"question^{question}\".format(**boosting), \"answer^{answer}\".format(**boosting), \"context^{context}\".format(**boosting)], # Give a boosting of 2 in the question field\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"company\": company\n",
    "                    }\n",
    "                }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    # Query the Elastic Search \n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    # Parse the response of elastic search\n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        results.append(hit['_source'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all the possible boosting combinations\n",
    "boosting_pairs =[\n",
    "{'question': 1, 'answer': 1, 'context': 1},\n",
    "{'question': 2, 'answer': 1, 'context': 1},\n",
    "{'question': 3, 'answer': 1, 'context': 1},\n",
    "{'question': 1, 'answer': 2, 'context': 1},\n",
    "{'question': 1, 'answer': 3, 'context': 1},\n",
    "{'question': 1, 'answer': 1, 'context': 2},\n",
    "{'question': 1, 'answer': 1, 'context': 3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate different search_functions\n",
    "def keyword_evaluate(ground_truth, boosting):\n",
    "    relevance_total = []\n",
    "\n",
    "    for record in tqdm(ground_truth):\n",
    "        record_id = record['id']\n",
    "        # Extract the user query\n",
    "        question = record['question']\n",
    "        # Extract keyword for filtering the results\n",
    "        company = record['company']\n",
    "        # Create a request for each query in ground truth\n",
    "        results = keyword_search(question, company, boosting)\n",
    "        relevance = [d['id'] == record_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'question_boost': boosting['question'],\n",
    "        'answer_boost': boosting['answer'],\n",
    "        'context_boost': boosting['context'],\n",
    "        'hit_rate': round((hit_rate(relevance_total)*100),2),\n",
    "        'mrr': round((mrr(relevance_total)*100),2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5175/5175 [00:56<00:00, 92.41it/s] \n",
      "100%|██████████| 5175/5175 [00:52<00:00, 97.75it/s] \n",
      "100%|██████████| 5175/5175 [00:57<00:00, 89.32it/s] \n",
      "100%|██████████| 5175/5175 [00:54<00:00, 95.16it/s] \n",
      "100%|██████████| 5175/5175 [00:52<00:00, 99.22it/s] \n",
      "100%|██████████| 5175/5175 [00:54<00:00, 94.23it/s] \n",
      "100%|██████████| 5175/5175 [00:53<00:00, 96.83it/s] \n"
     ]
    }
   ],
   "source": [
    "keyword_results = []\n",
    "# Evaluate all possible combinations of keyword search to choose the best one\n",
    "for boosting_pair in boosting_pairs:\n",
    "    keyword_results.append(keyword_evaluate(ground_truth, boosting_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_boost</th>\n",
       "      <th>answer_boost</th>\n",
       "      <th>context_boost</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88.58</td>\n",
       "      <td>78.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85.93</td>\n",
       "      <td>74.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.21</td>\n",
       "      <td>72.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>81.14</td>\n",
       "      <td>66.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72.70</td>\n",
       "      <td>58.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85.04</td>\n",
       "      <td>70.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>83.46</td>\n",
       "      <td>69.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_boost  answer_boost  context_boost  hit_rate    mrr\n",
       "0               1             1              1     88.58  78.01\n",
       "1               2             1              1     85.93  74.03\n",
       "2               3             1              1     84.21  72.01\n",
       "3               1             2              1     81.14  66.77\n",
       "4               1             3              1     72.70  58.75\n",
       "5               1             1              2     85.04  70.70\n",
       "6               1             1              3     83.46  69.40"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results\n",
    "keyword_findings = pd.DataFrame(keyword_results)\n",
    "# Display the results\n",
    "keyword_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_findings.to_csv('keyword_findings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the selected model to create the embeddings\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# Create an initial vector / embedding of the answer using the model\n",
    "res = model.encode(ground_truth[0]['question'])\n",
    "# Find the dimensionality of this vector\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [23:58<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the embeddings for each record in our QA dataset\n",
    "for record in tqdm(records):\n",
    "    # Extract the text fields you want to embed along with threir combinations\n",
    "    question = record['question']\n",
    "    answer = record['answer']\n",
    "    context = record['context']\n",
    "    question_answer = question + ' ' + answer\n",
    "    answer_context = answer + ' ' + context\n",
    "    question_context = question + ' ' + context\n",
    "    question_answer_context = question + ' ' + answer + ' ' + context\n",
    "    \n",
    "    # Create the embedding for each text field\n",
    "    record['question_vector'] = model.encode(question)\n",
    "    record['answer_vector'] = model.encode(answer)\n",
    "    record['context_vector'] = model.encode(context)\n",
    "    record['question_answer_vector'] = model.encode(question_answer)\n",
    "    record['answer_context_vector'] = model.encode(answer_context)\n",
    "    record['question_context_vector'] = model.encode(question_context)\n",
    "    record['question_answer_context_vector'] = model.encode(question_answer_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'investment-info'}\n"
     ]
    }
   ],
   "source": [
    "# Create the Schema of the Elastic Search Index for vector search\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"context\": {\"type\": \"text\"},\n",
    "            \"ticker\": {\"type\": \"keyword\"}, \n",
    "            \"company\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,     \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_answer_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"investment-info\"\n",
    "# Check if the index exists\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    # Delete the existing index\n",
    "    es_client.indices.delete(index=index_name)\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [00:51<00:00, 136.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fetch all the documents into the elastic search index\n",
    "for record in tqdm(records):\n",
    "    es_client.index(index = index_name, document=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new elastic seach query for the vector search\n",
    "\n",
    "def vector_search(field, vector, company):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"company\": company\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": ['question', 'answer', 'context', 'ticker' ,'company' ,'id']\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5175/5175 [01:27<00:00, 58.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the embeddings for the ground truth to use for validations\n",
    "for record in tqdm(ground_truth):\n",
    "    # Extract the question for each record\n",
    "    question = record['question']\n",
    "    # Create the embedding of each user query and store it in the ground truth records\n",
    "    record['question_vector'] = model.encode(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate different search_functions\n",
    "def vector_evaluate(ground_truth, field):\n",
    "    relevance_total = []\n",
    "\n",
    "    for record in tqdm(ground_truth):\n",
    "        record_id = record['id']\n",
    "        # Extract the vector field\n",
    "        question = record['question_vector']\n",
    "        # Extract keyword for filtering the results\n",
    "        company = record['company']\n",
    "        # Create a request for each query in ground truth\n",
    "        results = vector_search(field, question, company)\n",
    "        relevance = [d['id'] == record_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'field': field,\n",
    "        'hit_rate': round((hit_rate(relevance_total)*100),2),\n",
    "        'mrr': round((mrr(relevance_total)*100),2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list all possible combinations of vector search\n",
    "field_list = ['question_vector','answer_vector','context_vector',\n",
    "'question_answer_vector','answer_context_vector',\n",
    "'question_context_vector','question_answer_context_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5175/5175 [00:46<00:00, 110.38it/s]\n",
      "100%|██████████| 5175/5175 [00:47<00:00, 109.92it/s]\n",
      "100%|██████████| 5175/5175 [00:47<00:00, 110.01it/s]\n",
      "100%|██████████| 5175/5175 [00:55<00:00, 93.01it/s] \n",
      "100%|██████████| 5175/5175 [01:05<00:00, 78.68it/s] \n",
      "100%|██████████| 5175/5175 [00:58<00:00, 88.40it/s] \n",
      "100%|██████████| 5175/5175 [01:01<00:00, 84.41it/s] \n"
     ]
    }
   ],
   "source": [
    "vector_results = []\n",
    "# Evaluate all possible combinations of vector search to choose the best one\n",
    "for field in field_list:\n",
    "    vector_results.append(vector_evaluate(ground_truth, field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>question_vector</td>\n",
       "      <td>86.42</td>\n",
       "      <td>74.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_vector</td>\n",
       "      <td>63.92</td>\n",
       "      <td>54.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_vector</td>\n",
       "      <td>82.34</td>\n",
       "      <td>67.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question_answer_vector</td>\n",
       "      <td>86.86</td>\n",
       "      <td>75.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_context_vector</td>\n",
       "      <td>84.62</td>\n",
       "      <td>72.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>question_context_vector</td>\n",
       "      <td>87.65</td>\n",
       "      <td>76.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>question_answer_context_vector</td>\n",
       "      <td>88.04</td>\n",
       "      <td>76.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            field  hit_rate    mrr\n",
       "0                 question_vector     86.42  74.40\n",
       "1                   answer_vector     63.92  54.51\n",
       "2                  context_vector     82.34  67.96\n",
       "3          question_answer_vector     86.86  75.48\n",
       "4           answer_context_vector     84.62  72.39\n",
       "5         question_context_vector     87.65  76.79\n",
       "6  question_answer_context_vector     88.04  76.64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results\n",
    "vector_findings = pd.DataFrame(vector_results)\n",
    "# Display the results\n",
    "vector_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_findings.to_csv('vector_findings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the ES query for hybrid search with the best of two options\n",
    "def hybrid_search(a , query, vector, company):\n",
    "    # This is the query for the vector search with the best field \n",
    "    vector_query = {\n",
    "        \"field\": 'question_answer_context_vector',\n",
    "        \"query_vector\": vector, # This will recieve a vector of the user query\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": a, # Here you can set up the weight the vector search will have in the results\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"company\": company\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # This is the query for the keyword search with best boosting\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query, # This will recieve the user query itself\n",
    "                    \"fields\": [\"question\", \"answer\", \"context\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 1-a, # Here you can set up the weight the keyword search will have in the results\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"company\": company\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Here is the combination of the two search methods\n",
    "    search_query = {\n",
    "        \"knn\": vector_query,\n",
    "        \"query\": keyword_query,\n",
    "        \"size\": 5,   # This is the number of the returned documents\n",
    "        \"_source\": ['question', 'answer', 'context', 'ticker' ,'company' ,'id'] # The fields that will be returned for each retrieved document \n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate different search_functions\n",
    "def hybrid_evaluate(ground_truth, a):\n",
    "    relevance_total = []\n",
    "\n",
    "    for record in tqdm(ground_truth):\n",
    "        record_id = record['id']\n",
    "        # Extract the vector field\n",
    "        question = record['question']\n",
    "        vector = record['question_vector']\n",
    "        # Extract keyword for filtering the results\n",
    "        company = record['company']\n",
    "        # Create a request for each query in ground truth\n",
    "        results = hybrid_search(a , question, vector, company)\n",
    "        relevance = [d['id'] == record_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'vector_boosting': a,\n",
    "        'keyword_boosting': 1-a,\n",
    "        'hit_rate': round((hit_rate(relevance_total)*100),2),\n",
    "        'mrr': round((mrr(relevance_total)*100),2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of potential weights for each method\n",
    "a_values = [1.0, 0.75, 0.5, 0.25, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5175/5175 [01:03<00:00, 81.56it/s] \n",
      "100%|██████████| 5175/5175 [01:09<00:00, 74.19it/s] \n",
      "100%|██████████| 5175/5175 [01:14<00:00, 69.64it/s]\n",
      "100%|██████████| 5175/5175 [01:11<00:00, 72.13it/s]\n",
      "100%|██████████| 5175/5175 [01:04<00:00, 79.90it/s] \n"
     ]
    }
   ],
   "source": [
    "hybrid_results = []\n",
    "# Evaluate all possible combinations of hybrid search to choose the best one\n",
    "for a in a_values:\n",
    "    hybrid_results.append(hybrid_evaluate(ground_truth, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector_boosting</th>\n",
       "      <th>keyword_boosting</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88.04</td>\n",
       "      <td>76.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90.59</td>\n",
       "      <td>79.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>89.49</td>\n",
       "      <td>78.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>88.77</td>\n",
       "      <td>78.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>88.58</td>\n",
       "      <td>78.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vector_boosting  keyword_boosting  hit_rate    mrr\n",
       "0             1.00              0.00     88.04  76.64\n",
       "1             0.75              0.25     90.59  79.97\n",
       "2             0.50              0.50     89.49  78.86\n",
       "3             0.25              0.75     88.77  78.41\n",
       "4             0.00              1.00     88.58  78.01"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the results in a Dataframe\n",
    "hybrid_findings = pd.DataFrame(hybrid_results)\n",
    "# Display the results\n",
    "hybrid_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_findings.to_csv('hybrid_findings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings for the best retrieval method\n",
    "\n",
    "- Hybrid method with 0.75 weight to the vector search and 0.25 weight to the keyword search\n",
    "    - Keyword search: No boosted was used for any text field - best results\n",
    "    - Vector search: An embedding of a combination of question, answer and context was used - best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMZoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
