{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QA dataset to index\n",
    "data = pd.read_csv('../data/investment_data.csv') # Could be the sample \n",
    "records = data.to_dict(orient='records')\n",
    "# Load the ground truth dataset\n",
    "ground_truth_df = pd.read_csv('ground_truth.csv')\n",
    "ground_truth = ground_truth_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Ranking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'investment-info'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the client \n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Create the Schema of the Elastic Search Index for Keyword search\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"context\": {\"type\": \"text\"},\n",
    "            \"ticker\": {\"type\": \"keyword\"}, \n",
    "            \"company\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"investment-info\"\n",
    "# Check if the index exists\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    # Delete the existing index\n",
    "    es_client.indices.delete(index=index_name)\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [00:13<00:00, 510.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fetch all the documents into the elastic search index\n",
    "for record in tqdm(records):\n",
    "    es_client.index(index = index_name, document=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameteres to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a keyword search function to retrieve document form the elastic search\n",
    "def keyword_search(query, company):\n",
    "    # Create the query\n",
    "    search_query = {\n",
    "        # Specifying the number of documents to be retrieved\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        # Add the user query\n",
    "                        \"query\": query,\n",
    "                        # Include the text fields to search\n",
    "                        \"fields\": [\"question^2\", \"answer\", \"context\"], # Give a boosting of 2 in the question field\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"company\": company\n",
    "                    }\n",
    "                }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    # Query the Elastic Search \n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    # Parse the response of elastic search\n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        results.append(hit['_source'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the selected model to create the embeddings\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# Create an initial vector / embedding of the answer using the model\n",
    "res = model.encode(ground_truth[0]['question'])\n",
    "# Find the dimensionality of this vector\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>ticker</th>\n",
       "      <th>filing</th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023_10K</td>\n",
       "      <td>Nvidia Corporation</td>\n",
       "      <td>4f2ccc3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023_10K</td>\n",
       "      <td>Nvidia Corporation</td>\n",
       "      <td>ee4ed04f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023_10K</td>\n",
       "      <td>Nvidia Corporation</td>\n",
       "      <td>7eac6b57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023_10K</td>\n",
       "      <td>Nvidia Corporation</td>\n",
       "      <td>eb49bbd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2023_10K</td>\n",
       "      <td>Nvidia Corporation</td>\n",
       "      <td>3e4c199c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context ticker    filing  \\\n",
       "0  Since our original focus on PC graphics, we ha...   NVDA  2023_10K   \n",
       "1  Some of the most recent applications of GPU-po...   NVDA  2023_10K   \n",
       "2  Our invention of the GPU in 1999 defined moder...   NVDA  2023_10K   \n",
       "3  NVIDIA has a platform strategy, bringing toget...   NVDA  2023_10K   \n",
       "4  With our introduction of the CUDA programming ...   NVDA  2023_10K   \n",
       "\n",
       "              company        id  \n",
       "0  Nvidia Corporation  4f2ccc3b  \n",
       "1  Nvidia Corporation  ee4ed04f  \n",
       "2  Nvidia Corporation  7eac6b57  \n",
       "3  Nvidia Corporation  eb49bbd0  \n",
       "4  Nvidia Corporation  3e4c199c  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990/6990 [23:58<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the embeddings for each record in our QA dataset\n",
    "for record in tqdm(records):\n",
    "    # Extract the text fields you want to embed along with threir combinations\n",
    "    question = record['question']\n",
    "    answer = record['answer']\n",
    "    context = record['context']\n",
    "    question_answer = question + ' ' + answer\n",
    "    answer_context = answer + ' ' + context\n",
    "    question_context = question + ' ' + context\n",
    "    question_answer_context = question + ' ' + answer + ' ' + context\n",
    "    \n",
    "    # Create the embedding for each text field\n",
    "    record['question_vector'] = model.encode(question)\n",
    "    record['answer_vector'] = model.encode(answer)\n",
    "    record['context_vector'] = model.encode(context)\n",
    "    record['question_answer_vector'] = model.encode(question_answer)\n",
    "    record['answer_context_vector'] = model.encode(answer_context)\n",
    "    record['question_context_vector'] = model.encode(question_context)\n",
    "    record['question_answer_context_vector'] = model.encode(question_answer_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'investment-info'}\n"
     ]
    }
   ],
   "source": [
    "# Create the Schema of the Elastic Search Index for vector search\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,     \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_answer_context_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,             \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"investment-info\"\n",
    "# Check if the index exists\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    # Delete the existing index\n",
    "    es_client.indices.delete(index=index_name)\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the documents into the elastic search index\n",
    "for record in tqdm(records):\n",
    "    es_client.index(index = index_name, document=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new elastic seach query for the vector search\n",
    "\n",
    "def vector_search(field, vector, company):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"company\": company\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": ['question', 'answer', 'context', 'ticker' ,'company', ,'id']\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embeddings for the ground truth to use for validations\n",
    "for record in tqdm(ground_truth):\n",
    "    # Extract the question for each record\n",
    "    question = record['question']\n",
    "    # Create the embedding of each user query and store it in the ground truth records\n",
    "    record['question_vector'] = model.encode(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMZoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
